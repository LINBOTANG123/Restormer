{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef9689c9",
   "metadata": {},
   "source": [
    "\n",
    "# fastMRI Multicoil → Image-Space Gaussian Noise (Step-by-Step)\n",
    "\n",
    "This notebook helps you:\n",
    "1. **Load** fastMRI brain multicoil `.h5` files\n",
    "2. **Reconstruct** per-coil magnitude images from k-space\n",
    "3. **(Optional) Normalize** intensities by a percentile\n",
    "4. **Add Gaussian noise** in image space with a chosen `sigma`\n",
    "5. **Save** the noisy inputs and noise std maps for your inference script\n",
    "\n",
    "> Tip: Run cell-by-cell and inspect outputs at each step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cb0abd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ------------- FFT helpers -------------\n",
    "def ifft2c(kspace: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Centered 2D inverse FFT with orthonormal scaling over last two axes.\"\"\"\n",
    "    x = np.fft.ifftshift(kspace, axes=(-2, -1))\n",
    "    x = np.fft.ifft2(x, axes=(-2, -1), norm='ortho')\n",
    "    x = np.fft.fftshift(x, axes=(-2, -1))\n",
    "    return x\n",
    "\n",
    "def mag_per_coil_from_kspace(ks: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"ks: (S, C, H, W) complex -> returns (H, W, C, S) float32 magnitudes.\"\"\"\n",
    "    img = ifft2c(ks)                 # (S, C, H, W) complex\n",
    "    mag = np.abs(img).astype(np.float32)\n",
    "    return np.transpose(mag, (2, 3, 1, 0))  # (H, W, C, S)\n",
    "\n",
    "def rss_combine(mag_coils: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Root-sum-of-squares across coils. mag_coils: (H, W, C).\"\"\"\n",
    "    return np.sqrt(np.sum(mag_coils**2, axis=2))\n",
    "\n",
    "def normalize_by_percentile(vol: np.ndarray, percentile: float):\n",
    "    \"\"\"Scale so that the given percentile maps to 1.0, then clip to [0,1].\"\"\"\n",
    "    p = np.percentile(vol, percentile)\n",
    "    sf = 1.0 / (p + 1e-12)\n",
    "    return np.clip(vol * sf, 0.0, 1.0), sf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dc6494b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 .h5 file(s).\n",
      "[0] /n/netscratch/zickler_lab/Lab/linbo/denoising_project/dataset/fastmri_brain_test/multicoil_test/file_brain_AXFLAIR_200_6002621.h5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==== USER CONFIG ====\n",
    "# Set to a directory containing .h5 files, or to a single .h5 path\n",
    "INPUT_PATH = \"/n/netscratch/zickler_lab/Lab/linbo/denoising_project/dataset/fastmri_brain_test/multicoil_test/file_brain_AXFLAIR_200_6002621.h5\"     # <-- EDIT ME\n",
    "OUTPUT_DIR = \"/n/netscratch/zickler_lab/Lab/linbo/denoising_project/Restormer/simulate_noise/fastmri/data\"         # <-- EDIT ME (will be created)\n",
    "CAP_PERCENTILE = 99.8                            # intensity cap percentile for normalization\n",
    "DO_NORMALIZE = True                              # set False to skip normalization\n",
    "SIGMA = 0.02                                     # Gaussian noise std (if normalized, in [0,1] units)\n",
    "SEED = 123                                       # set None for non-reproducible noise\n",
    "SLICE_INDEX = 0                                  # which slice to visualize\n",
    "COIL_INDEX = 0                                   # which coil to visualize\n",
    "# =====================\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "if SEED is not None:\n",
    "    np.random.seed(SEED)\n",
    "\n",
    "# Find .h5 files\n",
    "if os.path.isdir(INPUT_PATH):\n",
    "    H5_FILES = sorted(glob.glob(os.path.join(INPUT_PATH, \"*.h5\")))\n",
    "elif INPUT_PATH.endswith(\".h5\"):\n",
    "    H5_FILES = [INPUT_PATH]\n",
    "else:\n",
    "    H5_FILES = []\n",
    "\n",
    "print(f\"Found {len(H5_FILES)} .h5 file(s).\")\n",
    "for i, p in enumerate(H5_FILES[:10]):\n",
    "    print(f\"[{i}] {p}\")\n",
    "if len(H5_FILES) == 0:\n",
    "    print(\"→ Update INPUT_PATH above to a valid folder or .h5 file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7bdf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pick the first file (or change index here)\n",
    "FILE_INDEX = 0\n",
    "if len(H5_FILES) == 0:\n",
    "    raise SystemExit(\"No .h5 files found. Please update INPUT_PATH and re-run.\")\n",
    "\n",
    "fpath = H5_FILES[FILE_INDEX]\n",
    "print(\"Using file:\", fpath)\n",
    "\n",
    "with h5py.File(fpath, 'r') as f:\n",
    "    print(\"Keys in file:\", list(f.keys()))\n",
    "    if 'kspace' not in f:\n",
    "        raise KeyError(\"This file doesn't contain 'kspace'.\")\n",
    "    ks = f['kspace'][()]  # shape (S, C, H, W), complex\n",
    "    print(\"kspace shape (S, C, H, W):\", ks.shape)\n",
    "\n",
    "S, C, H, W = ks.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858b03c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reconstruct per-coil magnitude (H, W, C, S)\n",
    "mag_vol = mag_per_coil_from_kspace(ks)\n",
    "print(\"Per-coil magnitude shape (H, W, C, S):\", mag_vol.shape)\n",
    "print(\"Stats clean  p10=%.4g  mean=%.4g  p90=%.4g  max=%.4g\" % (\n",
    "    np.percentile(mag_vol, 10), mag_vol.mean(), np.percentile(mag_vol, 90), mag_vol.max()\n",
    "))\n",
    "\n",
    "# Visualize RSS and one coil for SLICE_INDEX\n",
    "SLICE_INDEX = int(min(max(SLICE_INDEX, 0), S-1))\n",
    "COIL_INDEX  = int(min(max(COIL_INDEX, 0), C-1))\n",
    "\n",
    "rss = rss_combine(mag_vol[..., SLICE_INDEX])\n",
    "plt.figure()\n",
    "plt.title(f\"Clean RSS (slice {SLICE_INDEX})\")\n",
    "plt.imshow(rss, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "coil_img = mag_vol[..., COIL_INDEX, SLICE_INDEX]\n",
    "plt.figure()\n",
    "plt.title(f\"Clean Coil {COIL_INDEX} (slice {SLICE_INDEX})\")\n",
    "plt.imshow(coil_img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2b7d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if DO_NORMALIZE:\n",
    "    mag_norm, scale_factor = normalize_by_percentile(mag_vol, CAP_PERCENTILE)\n",
    "else:\n",
    "    mag_norm, scale_factor = mag_vol, 1.0\n",
    "\n",
    "print(f\"\"\"Normalization:\n",
    "  enabled    : {DO_NORMALIZE}\n",
    "  percentile : {CAP_PERCENTILE}\n",
    "  scale_fact.: {scale_factor:.3e}\n",
    "  stats      : min={mag_norm.min():.4g} max={mag_norm.max():.4g} mean={mag_norm.mean():.4g}\n",
    "\"\"\".rstrip())\n",
    "\n",
    "plt.figure()\n",
    "plt.title(f\"Normalized RSS (slice {SLICE_INDEX})\")\n",
    "plt.imshow(rss_combine(mag_norm[..., SLICE_INDEX]), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214737d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SIGMA = float(SIGMA)\n",
    "noise = np.random.normal(loc=0.0, scale=SIGMA, size=mag_norm.shape).astype(np.float32)\n",
    "noisy = mag_norm + noise\n",
    "noisy = np.clip(noisy, 0.0, 1.0) if DO_NORMALIZE else np.clip(noisy, 0.0, None)\n",
    "\n",
    "print(\"Noisy stats: min=%.4g max=%.4g mean=%.4g (SIGMA=%.4g)\" % (noisy.min(), noisy.max(), noisy.mean(), SIGMA))\n",
    "\n",
    "plt.figure()\n",
    "plt.title(f\"Noisy RSS (slice {SLICE_INDEX})\")\n",
    "plt.imshow(rss_combine(noisy[..., SLICE_INDEX]), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(f\"Noisy Coil {COIL_INDEX} (slice {SLICE_INDEX})\")\n",
    "plt.imshow(noisy[..., COIL_INDEX, SLICE_INDEX], cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1263d2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare outputs\n",
    "base = os.path.splitext(os.path.basename(fpath))[0]\n",
    "out_noisy = os.path.join(OUTPUT_DIR, f\"{base}_noisy.nii.gz\")\n",
    "out_noise = os.path.join(OUTPUT_DIR, f\"{base}_noise_std.nii.gz\")\n",
    "out_clean = os.path.join(OUTPUT_DIR, f\"{base}_clean.nii.gz\")\n",
    "\n",
    "# Noise std map: constant sigma everywhere\n",
    "noise_std_map = np.full(mag_norm.shape, SIGMA, dtype=np.float32)\n",
    "\n",
    "# Expand noisy to (H, W, C, S, 1) for your inference pipeline (N=1)\n",
    "noisy_5d = noisy[..., None]\n",
    "clean_5d = mag_norm[..., None]\n",
    "\n",
    "nib.save(nib.Nifti1Image(noisy_5d.astype(np.float32, copy=False), np.eye(4)), out_noisy)\n",
    "nib.save(nib.Nifti1Image(noise_std_map.astype(np.float32, copy=False), np.eye(4)), out_noise)\n",
    "nib.save(nib.Nifti1Image(clean_5d.astype(np.float32, copy=False), np.eye(4)), out_clean)\n",
    "\n",
    "print(\"Wrote:\")\n",
    "print(\"  \", out_noisy, \"  (H,W,C,S,1)\")\n",
    "print(\"  \", out_noise, \"  (H,W,C,S)\")\n",
    "print(\"  \", out_clean, \"  (H,W,C,S,1)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ac2a00",
   "metadata": {},
   "source": [
    "\n",
    "## Notes\n",
    "- If you want per-slice **different** noise levels, change `noise_std_map` to vary along `S` and regenerate `noise` accordingly.\n",
    "- If you disable normalization (`DO_NORMALIZE=False`), set `SIGMA` in **raw units**.\n",
    "- For batching many files, wrap the above workflow in a loop over `H5_FILES`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "restomer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
